{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.insert(0, '/home/todor/emotion_recognition/facenet')\n",
    "from facenet.src.load_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1751, 160, 160, 3)\n",
      "(9801, 160, 160, 3)\n",
      "(431, 160, 160, 3)\n",
      "(431,)\n"
     ]
    }
   ],
   "source": [
    "X_train2 = np.load('data/SFEW_2/Train/train_aug2.npy')\n",
    "y_train2 = np.load('data/SFEW_2/Train/train_aug2_labels.npy')\n",
    "X_train10 = np.load('data/SFEW_2/Train/train_aug10.npy')\n",
    "y_train10 = np.load('data/SFEW_2/Train/train_aug10_labels.npy')\n",
    "X_val = np.load('data/SFEW_2/Val/val.npy')\n",
    "y_val = np.load('data/SFEW_2/Val/val_labels.npy')\n",
    "\n",
    "X_train2 = X_train2.astype(np.float32)\n",
    "X_train10 = X_train10.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "\n",
    "print X_train2.shape\n",
    "print X_train10.shape\n",
    "print X_val.shape\n",
    "print y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data2: 0\n",
      "Data2: 1\n",
      "Data2: 2\n",
      "Data2: 3\n",
      "Data2: 4\n",
      "Data2: 5\n",
      "Data2: 6\n",
      "Data2: 7\n",
      "Data2: 8\n",
      "Data2: 9\n",
      "Data2: 10\n",
      "Data2: 11\n",
      "Data2: 12\n",
      "Data2: 13\n",
      "Data2: 14\n",
      "Data2: 15\n",
      "Data2: 16\n",
      "Data2: 17\n",
      "Data10: 0\n",
      "Data10: 1\n",
      "Data10: 2\n",
      "Data10: 3\n",
      "Data10: 4\n",
      "Data10: 5\n",
      "Data10: 6\n",
      "Data10: 7\n",
      "Data10: 8\n",
      "Data10: 9\n",
      "Data10: 10\n",
      "Data10: 11\n",
      "Data10: 12\n",
      "Data10: 13\n",
      "Data10: 14\n",
      "Data10: 15\n",
      "Data10: 16\n",
      "Data10: 17\n",
      "Data10: 18\n",
      "Data10: 19\n",
      "Data10: 20\n",
      "Data10: 21\n",
      "Data10: 22\n",
      "Data10: 23\n",
      "Data10: 24\n",
      "Data10: 25\n",
      "Data10: 26\n",
      "Data10: 27\n",
      "Data10: 28\n",
      "Data10: 29\n",
      "Data10: 30\n",
      "Data10: 31\n",
      "Data10: 32\n",
      "Data10: 33\n",
      "Data10: 34\n",
      "Data10: 35\n",
      "Data10: 36\n",
      "Data10: 37\n",
      "Data10: 38\n",
      "Data10: 39\n",
      "Data10: 40\n",
      "Data10: 41\n",
      "Data10: 42\n",
      "Data10: 43\n",
      "Data10: 44\n",
      "Data10: 45\n",
      "Data10: 46\n",
      "Data10: 47\n",
      "Data10: 48\n",
      "Data10: 49\n",
      "Data10: 50\n",
      "Data10: 51\n",
      "Data10: 52\n",
      "Data10: 53\n",
      "Data10: 54\n",
      "Data10: 55\n",
      "Data10: 56\n",
      "Data10: 57\n",
      "Data10: 58\n",
      "Data10: 59\n",
      "Data10: 60\n",
      "Data10: 61\n",
      "Data10: 62\n",
      "Data10: 63\n",
      "Data10: 64\n",
      "Data10: 65\n",
      "Data10: 66\n",
      "Data10: 67\n",
      "Data10: 68\n",
      "Data10: 69\n",
      "Data10: 70\n",
      "Data10: 71\n",
      "Data10: 72\n",
      "Data10: 73\n",
      "Data10: 74\n",
      "Data10: 75\n",
      "Data10: 76\n",
      "Data10: 77\n",
      "Data10: 78\n",
      "Data10: 79\n",
      "Data10: 80\n",
      "Data10: 81\n",
      "Data10: 82\n",
      "Data10: 83\n",
      "Data10: 84\n",
      "Data10: 85\n",
      "Data10: 86\n",
      "Data10: 87\n",
      "Data10: 88\n",
      "Data10: 89\n",
      "Data10: 90\n",
      "Data10: 91\n",
      "Data10: 92\n",
      "Data10: 93\n",
      "Data10: 94\n",
      "Data10: 95\n",
      "Data10: 96\n",
      "Data10: 97\n",
      "Data10: 98\n",
      "Val: 0\n",
      "Val: 1\n",
      "Val: 2\n",
      "Val: 3\n",
      "Val: 4\n"
     ]
    }
   ],
   "source": [
    "load_model('facenet/pre-trained/20170511-185253.pb')\n",
    "X = tf.get_default_graph().get_tensor_by_name('input:0')\n",
    "phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "fno1 = tf.get_default_graph().get_tensor_by_name('InceptionResnetV1/Logits/Dropout/cond/Merge:0')\n",
    "fno2 = tf.get_default_graph().get_tensor_by_name('InceptionResnetV1/Bottleneck/BatchNorm/batchnorm/add_1:0')\n",
    "fno3 = tf.get_default_graph().get_tensor_by_name('embeddings:0')\n",
    "\n",
    "o1_sz = fno1.get_shape()[1]\n",
    "o2_sz = fno2.get_shape()[1]\n",
    "o3_sz = fno3.get_shape()[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "t2_out1 = np.zeros((1751, o1_sz))\n",
    "t2_out2 = np.zeros((1751, o2_sz))\n",
    "t2_out3 = np.zeros((1751, o3_sz))\n",
    "t10_out1 = np.zeros((9801, o1_sz))\n",
    "t10_out2 = np.zeros((9801, o2_sz))\n",
    "t10_out3 = np.zeros((9801, o3_sz))\n",
    "v_out1 = np.zeros((431, o1_sz))\n",
    "v_out2 = np.zeros((431, o2_sz))\n",
    "v_out3 = np.zeros((431, o3_sz))\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in xrange(X_train2.shape[0] / batch_size + 1):\n",
    "    print 'Data2: ' + str(i)\n",
    "    si = i*batch_size\n",
    "    ei = min((i+1)*batch_size, X_train2.shape[0])\n",
    "    feed_dict2 = {X: X_train2[si:ei,:,:,:],\n",
    "                  phase_train_placeholder: False}\n",
    "    t2_out1[si:ei,:], t2_out2[si:ei,:], t2_out3[si:ei,:] = tf.Session().run([fno1, fno2, fno3],\n",
    "                                                                            feed_dict=feed_dict2)\n",
    "    \n",
    "for i in xrange(X_train10.shape[0] / batch_size + 1):\n",
    "    print 'Data10: ' + str(i)\n",
    "    si = i*batch_size\n",
    "    ei = min((i+1)*batch_size, X_train10.shape[0])\n",
    "    feed_dict10 = {X: X_train10[si:ei,:,:,:], \n",
    "                   phase_train_placeholder: False}\n",
    "    t10_out1[si:ei,:], t10_out2[si:ei,:], t10_out3[si:ei,:] = tf.Session().run([fno1, fno2, fno3],\n",
    "                                                                               feed_dict=feed_dict10)\n",
    "    \n",
    "for i in xrange(X_val.shape[0] / batch_size + 1):\n",
    "    print 'Val: ' + str(i)\n",
    "    si = i*batch_size\n",
    "    ei = min((i+1)*batch_size, X_val.shape[0])\n",
    "    feed_dict_val = {X: X_val[si:ei,:,:,:],\n",
    "                     phase_train_placeholder: False}\n",
    "    v_out1[si:ei,:], v_out2[si:ei,:], v_out3[si:ei,:] = tf.Session().run([fno1, fno2, fno3],feed_dict=feed_dict_val)\n",
    "\n",
    "train2_out = np.concatenate((t2_out1, t2_out2, t2_out3), axis=1)\n",
    "train10_out = np.concatenate((t10_out1, t10_out2, t10_out3), axis=1)\n",
    "val_out = np.concatenate((v_out1, v_out2, v_out3), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1751, 1792) (1751, 128) (1751, 128)\n"
     ]
    }
   ],
   "source": [
    "print t2_out1.shape, t2_out2.shape, t2_out3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('data/SFEW_2/Train/train2_features', train2_out)\n",
    "np.save('data/SFEW_2/Train/train10_features', train10_out)\n",
    "np.save('data/SFEW_2/Val/val_features', val_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9801, 2048)\n",
      "(1751, 2048)\n",
      "(431, 2048)\n"
     ]
    }
   ],
   "source": [
    "X_train10_features = np.load('data/SFEW_2/Train/train10_features.npy')\n",
    "X_train2_features = np.load('data/SFEW_2/Train/train2_features.npy')\n",
    "Xvf = np.load('data/SFEW_2/Val/val_features.npy')\n",
    "\n",
    "print X_train2_features.shape\n",
    "print X_train10_features.shape\n",
    "print Xvf.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
